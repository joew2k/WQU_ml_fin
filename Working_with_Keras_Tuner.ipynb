{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqFYXA8qPUhMj9tvJzu78l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joew2k/WQU_ml_fin/blob/main/Working_with_Keras_Tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The keras Tunner is a library that helps you pick the optimal set of hyper-parameters for your TensorFlow program\n",
        "\n",
        "There are two types of hyperparameters:\n",
        "- *Model Hyperparameters:* Which influence model selection such as the number and width of hidden layers\n",
        "- *Algorithm hyperparameters:* This influence the speed and qualityy of the learning algorithm such as learning rate for SGD and number of neighbors for a KNN classifier"
      ],
      "metadata": {
        "id": "sIi8D37Mhmoc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF-gsb_dhVvg",
        "outputId": "983e9438-340c-457e-c5f1-675cc47386d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "try:\n",
        "    import keras_tuner as kt\n",
        "except:\n",
        "    !pip install keras-tuner\n",
        "    import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and Prepare the Dataset\n",
        "# We will be using the Fashion MNIST dataset\n",
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahm5DODcjPVu",
        "outputId": "38a72676-81d5-4cf7-b06a-add2ad731019"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values between 0 and 1\n",
        "img_train = img_train.astype('float32') /  255.0\n",
        "img_test = img_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "DGHlN7_jj9S7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model\n",
        "When building a model for hypertuning, there is need to define the hyperparameter search space in addition to the model architecture. The model setup for hypertuning is call a hypermodel. This can be archieved in two ways\n",
        "1. Model builder function\n",
        "2. Subclassing the *HyperModel* class of the keras tuner API\n",
        "\n",
        "This program will be working with model bulder function to define the image classification model. The model builder function returns a compiled model and uses hyperparameters you define inline to hypertune the model."
      ],
      "metadata": {
        "id": "yKDzbfMQlRZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    # Tune the number of units in the first Dense layer\n",
        "    # Choose an optimal value between 32-512\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "\n",
        "    # Tune the learning rate for the optimizer\n",
        "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ABg8-dSGlF2Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate the tuner and perform hypertuning\n",
        "Instantiate the tuner to perform the hypertuning. The keras tuner has four tuners available *RandomSearch, Hyperband, BayesianOptimization* and *Sklearn*. **Hyperband** tuner will be used here"
      ],
      "metadata": {
        "id": "8J9u5B4Cpmr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(\n",
        "    model_builder,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='my_dir',\n",
        "    project_name ='intro_to_kt'\n",
        ")"
      ],
      "metadata": {
        "id": "g8Ky74STpdS2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a larger number of models for a few epochs and carries forward only the top performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing $1 + log_{factor}(max_epochs)$ and rounding it up to the nearest integer\n",
        "\n",
        "Create a callback to stop training early after reaching a certain value for the validation loss"
      ],
      "metadata": {
        "id": "3ELOAxGHrx7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "zLuadbE3rkb5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hyperparameter search. the arguments for the search method are the same as those used for t\n",
        "# tf.keras.model.fit in addition to the callback above\n",
        "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f'''The hyperparameter search is complete. The optimal number\n",
        " of units in the first densensly-connected layer is {best_hps.get('learning_rate')}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfK3miXBugs7",
        "outputId": "273a818d-6ddb-4740-f467-f32a8b0207dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hyperparameter search is complete. The optimal number\n",
            " of units in the first densensly-connected layer is 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "Find the optimal number of epochs to train the model with the hyperparameters obtained from the search"
      ],
      "metadata": {
        "id": "NgL_qlTd4aDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba9hZ67iyV-T",
        "outputId": "65f1745c-d640-461f-909f-0b420a8b60cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.5009 - accuracy: 0.8230 - val_loss: 0.4146 - val_accuracy: 0.8545\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.3740 - accuracy: 0.8635 - val_loss: 0.3782 - val_accuracy: 0.8639\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.3341 - accuracy: 0.8761 - val_loss: 0.3437 - val_accuracy: 0.8794\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.3085 - accuracy: 0.8869 - val_loss: 0.3314 - val_accuracy: 0.8787\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2925 - accuracy: 0.8919 - val_loss: 0.3541 - val_accuracy: 0.8717\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2738 - accuracy: 0.8993 - val_loss: 0.3468 - val_accuracy: 0.8796\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2601 - accuracy: 0.9021 - val_loss: 0.3146 - val_accuracy: 0.8877\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2504 - accuracy: 0.9069 - val_loss: 0.3453 - val_accuracy: 0.8805\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2384 - accuracy: 0.9106 - val_loss: 0.3173 - val_accuracy: 0.8892\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2294 - accuracy: 0.9149 - val_loss: 0.3275 - val_accuracy: 0.8876\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.2197 - accuracy: 0.9180 - val_loss: 0.3268 - val_accuracy: 0.8898\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2125 - accuracy: 0.9203 - val_loss: 0.3245 - val_accuracy: 0.8871\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2057 - accuracy: 0.9222 - val_loss: 0.3189 - val_accuracy: 0.8898\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1956 - accuracy: 0.9267 - val_loss: 0.3213 - val_accuracy: 0.8946\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1909 - accuracy: 0.9283 - val_loss: 0.3529 - val_accuracy: 0.8868\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1820 - accuracy: 0.9311 - val_loss: 0.3310 - val_accuracy: 0.8889\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1750 - accuracy: 0.9351 - val_loss: 0.3327 - val_accuracy: 0.8948\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1699 - accuracy: 0.9376 - val_loss: 0.3371 - val_accuracy: 0.8957\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1676 - accuracy: 0.9360 - val_loss: 0.3351 - val_accuracy: 0.8912\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1587 - accuracy: 0.9410 - val_loss: 0.3531 - val_accuracy: 0.8912\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1532 - accuracy: 0.9414 - val_loss: 0.3435 - val_accuracy: 0.8953\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1504 - accuracy: 0.9441 - val_loss: 0.3642 - val_accuracy: 0.8917\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1443 - accuracy: 0.9453 - val_loss: 0.3512 - val_accuracy: 0.8939\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1414 - accuracy: 0.9469 - val_loss: 0.3756 - val_accuracy: 0.8898\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.1361 - accuracy: 0.9485 - val_loss: 0.3719 - val_accuracy: 0.8938\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1373 - accuracy: 0.9483 - val_loss: 0.3580 - val_accuracy: 0.8978\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1268 - accuracy: 0.9523 - val_loss: 0.4087 - val_accuracy: 0.8873\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1267 - accuracy: 0.9536 - val_loss: 0.4031 - val_accuracy: 0.8903\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1230 - accuracy: 0.9530 - val_loss: 0.3835 - val_accuracy: 0.8968\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1165 - accuracy: 0.9561 - val_loss: 0.4111 - val_accuracy: 0.8939\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1166 - accuracy: 0.9562 - val_loss: 0.4062 - val_accuracy: 0.8919\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1143 - accuracy: 0.9570 - val_loss: 0.3859 - val_accuracy: 0.8970\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1107 - accuracy: 0.9583 - val_loss: 0.4043 - val_accuracy: 0.8935\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1095 - accuracy: 0.9588 - val_loss: 0.4479 - val_accuracy: 0.8904\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1049 - accuracy: 0.9602 - val_loss: 0.4823 - val_accuracy: 0.8768\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1045 - accuracy: 0.9604 - val_loss: 0.4270 - val_accuracy: 0.8943\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1013 - accuracy: 0.9617 - val_loss: 0.4465 - val_accuracy: 0.8915\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0972 - accuracy: 0.9642 - val_loss: 0.4618 - val_accuracy: 0.8861\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0953 - accuracy: 0.9647 - val_loss: 0.4745 - val_accuracy: 0.8962\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0983 - accuracy: 0.9619 - val_loss: 0.4646 - val_accuracy: 0.8907\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0932 - accuracy: 0.9649 - val_loss: 0.4779 - val_accuracy: 0.8910\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0882 - accuracy: 0.9678 - val_loss: 0.4870 - val_accuracy: 0.8895\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0876 - accuracy: 0.9671 - val_loss: 0.4480 - val_accuracy: 0.8986\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0864 - accuracy: 0.9670 - val_loss: 0.4961 - val_accuracy: 0.8947\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0855 - accuracy: 0.9680 - val_loss: 0.5264 - val_accuracy: 0.8881\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0851 - accuracy: 0.9672 - val_loss: 0.4868 - val_accuracy: 0.8951\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0818 - accuracy: 0.9696 - val_loss: 0.5076 - val_accuracy: 0.8960\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0794 - accuracy: 0.9697 - val_loss: 0.5200 - val_accuracy: 0.8943\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0779 - accuracy: 0.9709 - val_loss: 0.5631 - val_accuracy: 0.8916\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0776 - accuracy: 0.9709 - val_loss: 0.5399 - val_accuracy: 0.8924\n",
            "Best epoch: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-instantiate the hypermodel and train it with the optimal number of epochs from above"
      ],
      "metadata": {
        "id": "QCXAx0WS_p42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
      ],
      "metadata": {
        "id": "telemwuD56oB",
        "outputId": "075d0366-4c86-41cf-a23b-72f9da33d32f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/43\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4972 - accuracy: 0.8244 - val_loss: 0.4243 - val_accuracy: 0.8444\n",
            "Epoch 2/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3706 - accuracy: 0.8655 - val_loss: 0.3621 - val_accuracy: 0.8668\n",
            "Epoch 3/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3314 - accuracy: 0.8790 - val_loss: 0.3632 - val_accuracy: 0.8654\n",
            "Epoch 4/43\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.3082 - accuracy: 0.8855 - val_loss: 0.3409 - val_accuracy: 0.8748\n",
            "Epoch 5/43\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.2868 - accuracy: 0.8938 - val_loss: 0.3354 - val_accuracy: 0.8783\n",
            "Epoch 6/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2724 - accuracy: 0.8997 - val_loss: 0.3252 - val_accuracy: 0.8814\n",
            "Epoch 7/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2576 - accuracy: 0.9032 - val_loss: 0.3321 - val_accuracy: 0.8810\n",
            "Epoch 8/43\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2483 - accuracy: 0.9066 - val_loss: 0.3162 - val_accuracy: 0.8889\n",
            "Epoch 9/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2362 - accuracy: 0.9105 - val_loss: 0.3134 - val_accuracy: 0.8899\n",
            "Epoch 10/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2270 - accuracy: 0.9153 - val_loss: 0.3304 - val_accuracy: 0.8888\n",
            "Epoch 11/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2203 - accuracy: 0.9187 - val_loss: 0.3334 - val_accuracy: 0.8843\n",
            "Epoch 12/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2087 - accuracy: 0.9229 - val_loss: 0.3444 - val_accuracy: 0.8888\n",
            "Epoch 13/43\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2018 - accuracy: 0.9240 - val_loss: 0.3192 - val_accuracy: 0.8923\n",
            "Epoch 14/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1952 - accuracy: 0.9271 - val_loss: 0.3241 - val_accuracy: 0.8912\n",
            "Epoch 15/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1895 - accuracy: 0.9286 - val_loss: 0.3191 - val_accuracy: 0.8935\n",
            "Epoch 16/43\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1817 - accuracy: 0.9321 - val_loss: 0.3728 - val_accuracy: 0.8816\n",
            "Epoch 17/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1776 - accuracy: 0.9328 - val_loss: 0.3294 - val_accuracy: 0.8932\n",
            "Epoch 18/43\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1710 - accuracy: 0.9360 - val_loss: 0.3395 - val_accuracy: 0.8920\n",
            "Epoch 19/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1664 - accuracy: 0.9373 - val_loss: 0.3370 - val_accuracy: 0.8956\n",
            "Epoch 20/43\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1599 - accuracy: 0.9387 - val_loss: 0.3284 - val_accuracy: 0.8969\n",
            "Epoch 21/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1532 - accuracy: 0.9425 - val_loss: 0.3783 - val_accuracy: 0.8873\n",
            "Epoch 22/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1532 - accuracy: 0.9435 - val_loss: 0.3803 - val_accuracy: 0.8907\n",
            "Epoch 23/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1449 - accuracy: 0.9458 - val_loss: 0.3530 - val_accuracy: 0.8942\n",
            "Epoch 24/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1387 - accuracy: 0.9477 - val_loss: 0.3661 - val_accuracy: 0.8928\n",
            "Epoch 25/43\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1386 - accuracy: 0.9469 - val_loss: 0.3915 - val_accuracy: 0.8869\n",
            "Epoch 26/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1333 - accuracy: 0.9499 - val_loss: 0.3690 - val_accuracy: 0.8931\n",
            "Epoch 27/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1305 - accuracy: 0.9518 - val_loss: 0.3617 - val_accuracy: 0.8942\n",
            "Epoch 28/43\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1253 - accuracy: 0.9527 - val_loss: 0.4230 - val_accuracy: 0.8887\n",
            "Epoch 29/43\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1229 - accuracy: 0.9539 - val_loss: 0.3983 - val_accuracy: 0.8899\n",
            "Epoch 30/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1207 - accuracy: 0.9549 - val_loss: 0.4138 - val_accuracy: 0.8879\n",
            "Epoch 31/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1166 - accuracy: 0.9557 - val_loss: 0.4140 - val_accuracy: 0.8928\n",
            "Epoch 32/43\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1126 - accuracy: 0.9579 - val_loss: 0.4020 - val_accuracy: 0.8948\n",
            "Epoch 33/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1101 - accuracy: 0.9576 - val_loss: 0.4085 - val_accuracy: 0.8992\n",
            "Epoch 34/43\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1110 - accuracy: 0.9580 - val_loss: 0.4164 - val_accuracy: 0.8932\n",
            "Epoch 35/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1061 - accuracy: 0.9602 - val_loss: 0.4221 - val_accuracy: 0.8923\n",
            "Epoch 36/43\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1031 - accuracy: 0.9617 - val_loss: 0.4456 - val_accuracy: 0.8923\n",
            "Epoch 37/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1031 - accuracy: 0.9613 - val_loss: 0.4127 - val_accuracy: 0.8928\n",
            "Epoch 38/43\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0978 - accuracy: 0.9635 - val_loss: 0.4288 - val_accuracy: 0.8958\n",
            "Epoch 39/43\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0967 - accuracy: 0.9638 - val_loss: 0.5026 - val_accuracy: 0.8779\n",
            "Epoch 40/43\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0940 - accuracy: 0.9652 - val_loss: 0.4574 - val_accuracy: 0.8892\n",
            "Epoch 41/43\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0925 - accuracy: 0.9654 - val_loss: 0.4713 - val_accuracy: 0.8917\n",
            "Epoch 42/43\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0897 - accuracy: 0.9672 - val_loss: 0.4617 - val_accuracy: 0.8926\n",
            "Epoch 43/43\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0877 - accuracy: 0.9682 - val_loss: 0.4988 - val_accuracy: 0.8916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7db7f0443d00>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "id": "NYP-vnMBB2hn",
        "outputId": "c3a4cfc8-9ac9-4883-ab94-e7c1e37f113e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5517 - accuracy: 0.8907\n",
            "[test loss, test accuracy]: [0.5517007112503052, 0.8906999826431274]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u11CL1wiFCMc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}